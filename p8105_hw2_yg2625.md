p8105\_hw2\_yg2625
================
Yue Gu
October 2, 2018

Library
=======

``` r
library(tidyverse)
library(readxl)
```

Problem 1
=========

Data reading and cleaning
-------------------------

Read and clean the data and convert the entry variable from character to logical

``` r
NYCsub_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names(dat = .) %>% 
  select(.data = ., line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(.data = ., entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
NYCsub_data 
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu~ route1 route2
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr> 
    ##  1 4 Av~ 25th St                  40.7            -74.0 R      <NA>  
    ##  2 4 Av~ 25th St                  40.7            -74.0 R      <NA>  
    ##  3 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  4 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  5 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  6 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  7 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  8 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  9 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ## 10 4 Av~ 53rd St                  40.6            -74.0 R      <NA>  
    ## # ... with 1,858 more rows, and 13 more variables: route3 <chr>,
    ## #   route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>, route8 <int>,
    ## #   route9 <int>, route10 <int>, route11 <int>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

Resulting data description
--------------------------

From the data output, we could know it contains variables including line, station\_name, station\_latitude, station\_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance\_type, ada; And I clean the names to lower case and only keep the variables as required while converting the entry variable from character to logical; The dimension of the dataset is 1868, 19, the current data is not tidy.

Answering question with data
----------------------------

There are 356 distinct stations. And there are 468 stations are ADA compliant. And the proportion of station entrances/exits without vending allow entrance is 0.0369379

Reformat data
-------------

``` r
NYCsub_tidy_data = gather(NYCsub_data, key = route, value = route_name, route1:route11)
```

There are 3 stations serve the A train. And in these stations, 107 are ADA compliant.

Problem 2
=========

Mr. Trash Dataset
-----------------

Read and clean the data from Mr. Trash, specifying sheet. Renaming variable names, omitting rows and rounding numbers as required.

``` r
Healthy_data = 
  read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>%
  janitor::clean_names(dat = .) %>% 
  filter(.data = ., dumpster != "") %>% 
  rename(.data = ., weight = weight_tons, volume = volume_cubic_yards) %>% 
  mutate(.data = ., sports_balls = as.integer(round(sports_balls)))
```

Precipitation Dataset
---------------------

Read and clean precipitation data for 2016 and 2017. Omitting rows, adding variable year, combining datasets and converting month to character as required.

``` r
Prec_2016 =
  read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = cell_rows(2:15)) %>% 
  janitor::clean_names(dat = .) %>% 
  filter(.data = ., total != "") %>% 
  mutate(.data = ., year = "2016")

Prec_2017 =
  read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = cell_rows(2:15)) %>% 
  janitor::clean_names(dat = .) %>% 
  filter(.data = ., total != "") %>% 
  mutate(.data = ., year = "2017")

Prec_data = 
  left_join(Prec_2016, Prec_2017, by = "month") %>%
  filter(.data = ., month != "") %>% 
  mutate(.data = ., month = month.name)
```

The number of the observations in Mr. Trash is 285, in Precipitation for 2016 is 13, in Precipitation for 2017 is 13, in combined dataset for 2016-2007 precipitation is 12. The total precipitation in 2017 is 32.93 and the median of sports balls in a dumpster in 2016 is 8.

Problem 3
---------

Data reading and cleaning
-------------------------

Read and clean BRFSS data. Formating, filtering, excluding variables, structuring data and creating new variables as required.

``` r
library(p8105.datasets)
data(brfss_smart2010)
brfss_smart2010_tidy = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(.data = ., topic == "Overall Health") %>% 
  select(.data = ., -class, -topic, -question, -sample_size, -confidence_limit_low: -geo_location) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(.data = ., excellent_or_very_good = excellent + very_good) %>% 
  rename(.data = ., state = locationabbr, county = locationdesc)
```

Answering questions
-------------------

There are 404 distinct county and 51 distinct states.Since there are 51 states, all states are included. And yes, every state is represented.

``` r
arrange(count(brfss_smart2010_tidy, state), desc(n))
```

    ## # A tibble: 51 x 2
    ##    state     n
    ##    <chr> <int>
    ##  1 NJ      146
    ##  2 FL      122
    ##  3 NC      115
    ##  4 WA       97
    ##  5 MD       90
    ##  6 MA       79
    ##  7 TX       71
    ##  8 NY       65
    ##  9 SC       63
    ## 10 CO       59
    ## # ... with 41 more rows

From the output above, we know NJ state is observed the most. And the median of the "Excellent" response value is 23.6.

Histogram of "excellent" response in 2002
-----------------------------------------

``` r
ggplot(brfss_smart2010_tidy, aes(x = excellent)) +
  geom_histogram()
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

    ## Warning: Removed 6 rows containing non-finite values (stat_bin).

![](p8105_hw2_yg2625_files/figure-markdown_github/unnamed-chunk-8-1.png)

Scatterplot
-----------

Showing proportion of "Excellent" in NY and Queens County in each year from 2002 to 2010

``` r
brfss_smart2010_tidy_NQ = 
  brfss_smart2010_tidy %>% 
  filter(.data = ., county == "NY - Queens County" | state == "NY - New York County") %>% 
  select(.data = ., -fair:-excellent_or_very_good)

ggplot(brfss_smart2010_tidy_NQ, aes(x = year, y = excellent)) +
  geom_point(aes(color = county)) +
  theme(legend.position = "bottom")
```

![](p8105_hw2_yg2625_files/figure-markdown_github/unnamed-chunk-9-1.png)
