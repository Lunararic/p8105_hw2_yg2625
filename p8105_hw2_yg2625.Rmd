---
title: "p8105_hw2_yg2625"
author: "Yue Gu"
date: "October 2, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library
```{r, message = FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1
## Data reading and cleaning

Read and clean the data and convert the entry variable from character to logical
```{r}
NYCsub_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names(dat = .) %>% 
  select(.data = ., line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(.data = ., entry = ifelse(entry == "YES", TRUE, FALSE))

NYCsub_data 
```

## Resulting data description
From the data output, we could know it contains variables including `r names(NYCsub_data)`; And I clean the names to lower case and only keep the variables as required while converting the entry variable from character to logical; The dimension of the dataset is `r dim(NYCsub_data)`, the current data is not tidy.


## Answering question with data
There are `r count(distinct(NYCsub_data, station_name, line))` distinct stations. And there are `r count(distinct(subset(NYCsub_data, ada == TRUE), station_name, line))` stations are ADA compliant. And the proportion of station entrances/exits without vending allow entrance is `r count(subset(NYCsub_data, vending == "NO" & entry == TRUE))/count(subset(NYCsub_data, vending == "NO"))`


## Reformat data
```{r}
NYCsub_tidy_data = gather(NYCsub_data, key = route, value = route_name, route1:route11)
```

There are `r count(distinct(subset(NYCsub_tidy_data, route_name == "A"), station_name, line))` stations serve the A train. And in these stations, `r count(distinct(subset(NYCsub_tidy_data, route_name == "A" & ada == TRUE), station_name, line))` are ADA compliant.


# Problem 2
## Mr. Trash Dataset

Read and clean the data from Mr. Trash, specifying sheet. Renaming variable names, omitting rows and rounding numbers as required.
```{r}
Healthy_data = 
  read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>%
  janitor::clean_names(dat = .) %>% 
  filter(.data = ., dumpster != "") %>% 
  rename(.data = ., weight = weight_tons, volume = volume_cubic_yards) %>% 
  mutate(.data = ., sports_balls = as.integer(round(sports_balls)))
```

## Precipitation Dataset

Read and clean precipitation data for 2016 and 2017. Omitting rows, adding variable year, combining datasets and converting month to character as required.
```{r}
Prec_2016 =
  read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = cell_rows(2:14)) %>% 
  janitor::clean_names(dat = .) %>% 
  filter(.data = ., total != "") %>% 
  mutate(.data = ., year = "2016")

Prec_2017 =
  read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = cell_rows(2:14)) %>% 
  janitor::clean_names(dat = .) %>% 
  filter(.data = ., total != "") %>% 
  mutate(.data = ., year = "2017")

Prec_data = 
  bind_rows(Prec_2016, Prec_2017) %>%
  mutate(month = month.name[month])

```

The number of the observations in Mr. Trash is `r nrow(Healthy_data)`, in Precipitation for 2016 is `r nrow(Prec_2016)`, in Precipitation for 2017 is `r nrow(Prec_2017)`, in combined dataset for 2016-2007 precipitation is `r nrow(Prec_data)`. The total precipitation in 2017 is `r sum(Prec_2017$total)` and the median of sports balls in a dumpster in 2016 is `r median(subset(Healthy_data, year == 2016)$sports_balls)`.


## Problem 3
## Data reading and cleaning

Read and clean BRFSS data. Formating, filtering, excluding variables, structuring data and creating new variables as required.
```{r}
library(p8105.datasets)
data(brfss_smart2010)
brfss_smart2010_tidy = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(.data = ., topic == "Overall Health") %>% 
  select(.data = ., -class, -topic, -question, -sample_size, -confidence_limit_low: -geo_location) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(.data = ., excellent_or_very_good = excellent + very_good) %>% 
  rename(.data = ., state = locationabbr, county = locationdesc)
```

## Answering questions
There are `r count(distinct(brfss_smart2010_tidy, county))` distinct county and `r count(distinct(brfss_smart2010_tidy, state))` distinct states.Since there are 51 states, all states are included. And yes, every state is represented.

```{r}
arrange(count(brfss_smart2010_tidy, state), desc(n))
```
From the output above, we know NJ state is observed the most with 146 times. And the median of the "Excellent" response value is `r median(subset(brfss_smart2010_tidy, year == "2002")$excellent, na.rm = TRUE)`.

## Histogram of "excellent" response in 2002
```{r}
ggplot(subset(brfss_smart2010_tidy, year == 2002), aes(x = excellent)) +
  geom_histogram()
```

## Scatterplot
Showing proportion of "Excellent" in NY and Queens County in each year from 2002 to 2010
```{r}
brfss_smart2010_tidy_NQ = 
  brfss_smart2010_tidy %>% 
  filter(.data = ., county == "NY - Queens County" | county == "NY - New York County") %>% 
  select(.data = ., -fair:-excellent_or_very_good)

ggplot(brfss_smart2010_tidy_NQ, aes(x = year, y = excellent)) +
  geom_point(aes(color = county)) +
  theme(legend.position = "bottom")
```

